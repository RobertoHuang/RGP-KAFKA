# Kafka实战

## 关于Kafka

`Apache Kafka`是一种分布式的、基于发布/订阅的消息系统，由`Scala`语言编写。以下是`Kafka`主要特点

- `Kafka`具有近乎实时性的消息处理能力，即使面对海量消息也能够高效地存储消息和查询消息
- `Kafka`支持批量读写消息，并且会对消息进行压缩，这样既提高了网络利用率也提高了压缩率
- `Kafka`支持消息分区，每个分区中的消息保证顺序传输，而分区之间则可以并发操作提高了并发能力
- `Kafka`支持在线增加分区，支持在线水平扩展，支持多副本机制提高数据容灾能力

`Apache Kafka`与其他消息中间件的对比【[消息中间件选型分析:从Kafka与RabbitMQ的对比看全局](https://www.infoq.cn/article/kafka-vs-rabbitmq?utm_source=infoq&utm_medium=popular_widget&utm_campaign=popular_content_list&utm_content=homepage)】

## Kafka核心概念

`Kafka`的核心概念比较多，一言以蔽之是不大可能。若只是使用`Kafka API`可先了解如下概念即可

- `Topic`:消息的订阅和发送都是基于`Topic`，它像一个特定主题的收件箱(`Producer`往里丢`Consumer`取出)

- `Partition`:大多数消息系统同一个`Topic`下的消息存储在一个队列中，分区的概念就是把这个队列划分为若干个小队列，每一个小队列就是一个分区。分区之间可以并发操作提高了并发能力

- `Offset`:数据消费的偏移量，它是一个消息在一个`Partition`中的唯一标示，表示自己的消息顺序
- `Group`:消费组(为什么要有消费组的概念？队列都有单播、广播。广播在`Kafka`中就是让多个`Consumer`同时消费同一条消息的时候才用不同的`Group`、单播就是让多个`Consumer`在消费一条消息时使用一个`Group`)，同一个`Topic`的数据可以被多个`Group`消费，相互间不受影响。一个组内消费完数据不会重新消费

## Kafka消费者实战

- 引入`kafka-clients`依赖

  ```xml
  <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
  </dependency>
  ```

- 入门 - 最简单的消费者`Demo`

  ```java
  public class ConsumerTest {
      public static final String TOPIC = "topic-test";
      public static final String GROUP_ID = "group_id";
      public static final String CLIENT_ID = "client_id";
      public static final String BOOTSTRAP = "localhost:9092";
  
      public static void main(String[] args) {
          Properties properties = new Properties();
  
          // brokers地址
          properties.put("bootstrap.servers", BOOTSTRAP);
          properties.put("group.id", GROUP_ID);
          properties.put("client.id", CLIENT_ID);
          // 自动提交offset
          properties.put("enable.auto.commit", "true");
          // 自动提交时间间隔
          properties.put("auto.commit.interval.ms", "1000");
          properties.put("key.deserializer", StringDeserializer.class.getName());
          properties.put("value.deserializer", StringDeserializer.class.getName());
          //  设置消费从最新的开始消费。 最早未消费的数据。
          properties.put("auto.offset.reset", "earliest");
  
          KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
          Collection<String> topics = Arrays.asList(TOPIC);
          // assign跟subscribe区别：用户已经指定了消费分区，如果有消费者加入或退出，assign不会进行reblance
          // subscribe有个重载函数subscribe(Pattern pattern, ConsumerRebalanceListener listener)可用于监听reblance 有兴趣的同学可自行尝试
          // assign为consumer手动、显示的指定需要消费的topic-partitions，不受group.id限制，相当与指定的group无效
          // subscribe为consumer自动分配partition，有内部算法保证topic-partition以最优的方式均匀分配给同group下的不同consumer
          consumer.subscribe(topics);
          while (true) {
              ConsumerRecords<String, String> records = consumer.poll(100);
              records.forEach(record -> System.out.printf("client :%s , topic:%s , parititon :%d ,offset = %d  ,key =%s , value =%s%n", CLIENT_ID, record.topic(), record.partition(), record.offset(), record.key(), record.value()));
          }
      }
  }
  ```

- 入门 - 手动提交`Offset Demo`

  - 同步方式`SYNC`

    ```java
    consumer.commitSync(Map<TopicPartition, OffsetAndMetadata> offsets)
    ```

  - 异步方式`ASYNC`

    ```java
    1.consumer.commitAsync()
        
    2.consumer.commitAsync(OffsetCommitCallback callback)
    
    3.consumer.commitAsync(Map<TopicPartition, OffsetAndMetadata> offsets, callback)
    ```

  刚接触`Kafka`的同学可能不理解为什么要提交`Offset`，提交`Offset`主要是告知`Broker`哪些消息已经被消费

- 数据回溯消费 - 从指定`Offset`开始消费

  ```reStructuredText
  1.Kafka为数据回溯消费提供两种方式，分别是Offset和Timestamp
  
  2.如果已知Offset则直接使用consumer.seek(TopicPartition partition, long offset)指定
  
  3.如果提供Timestamp则需要根据Timestamp找到对应的Offset再调用上述API，方法如下
      Map<TopicPartition, Long> timestampsToSearch = new HashMap<>();
      timestampsToSearch.put(new TopicPartition(topic, 0), System.currentTimeMillis() -10*1000);
      Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes = consumer.offsetsForTimes(timestampsToSearch);
  ```

## Kafka生成者实战

- 引入`kafka-clients`依赖

  ```xml
  <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
  </dependency>
  ```

- 入门 - 最简单的生产者`Demo`

  ```java
  public class ProducerTest {
      public static final String TOPIC = "topic-test";
      public static final String BOOTSTRAP = "localhost:9092";
  
      public static void main(String[] args) throws InterruptedException {
          Properties properties = new Properties();
          properties.setProperty("bootstrap.servers", BOOTSTRAP);
          properties.setProperty("key.serializer", StringSerializer.class.getName());
          properties.setProperty("value.serializer", StringSerializer.class.getName());
          // acks - 0 发出数据不进行ACK确认消息是否发送成功
          // acks - 1 当Leader已经确认这条消息已经写入到日志文件，但是并没有等待所有的follower进行数据同步。这钟情况下会有少数情况数据丢失
          // acks - all 这跟上面一种情况相似，当所有的除了leader还有其他的ISR集合中的follower都成功将数据的写入文件。这种情况下数据可靠性最强
          properties.setProperty("acks", "1");
          // 消息批次大小
          properties.setProperty("batch.size", "10000");
          // 消息发送缓冲区大小
          properties.put("buffer.memory", 1 * 1024* 1024);
          // 如果消息发送失败，最多进行重试多少次
          properties.setProperty("retries", "3");
          KafkaProducer<Object, Object> kafkaProducer = new KafkaProducer<>(properties);
          for (int i = 0; i < 100; i++) {
              kafkaProducer.send(new ProducerRecord<>(TOPIC, Integer.toString(i), "message-" + i), (metadata, exception) -> System.out.printf(" msg ==> partition :%d  , offset :%d ,topic :%s , valuesize: %d %n", metadata.partition(), metadata.offset(), metadata.topic(), metadata.serializedValueSize()));
          }
          Thread.sleep(100000);
      }
  }
  ```

- 生产者实战拦截器 - 对消息进行前后置处理

  ```reStructuredText
  1.实现ProducerInterceptor接口，实现对应方法
  
  2.为生产者添加配置属性 如:properties.put("interceptor.classes", xxx.class.getName());
  ```

- 将消息按照一定规则路由到指定`Partition`

  ```reStructuredText
  1.实现Partitioner接口重写对应方法
  
  2.为生产者添加配置属性 如:properties.put("partitioner.class", xxx.class.getName());
  ```

- `Kafka`集成`Protostuff`进行序列化

  自定义`Kafka`序列化方式可参考:[kafka自定义消息序列化和反序列化方式](https://blog.csdn.net/shirukai/article/details/82152172)